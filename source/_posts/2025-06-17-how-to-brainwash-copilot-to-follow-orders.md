---
title: '如何给 GitHub Copilot "洗脑”，让 AI 精准遵循指令产出高质量代码'
date: 2025-06-17 10:00:00
tags:
  - AI
  - GitHub Copilot
  - 软件开发
  - 代码质量
  - 提示工程
categories:
  - 技术思考
---

## 引子：把 AI 新兵改造成精锐士兵

GitHub Copilot 就像一个天赋异禀但野路子出身的“新兵”。它枪法精准（编码能力强），但缺乏战场纪律（工程规范）。

你让它冲锋，它能迅速拿下山头，但阵地上一片狼藉：没有构筑工事（错误处理），不关心侧翼安全（边界情况），弹药随意堆放（命名混乱）。

我们需要的不是一个只会冲锋的“莽夫”，而是一个懂得协同作战、遵守战场纪律的“精锐士兵”。因此，我决定为它编写一套严格的“作战条令”（Prompts），对它进行一次彻底的“军事化改造”，让它乖乖听话。

## 不是魔法，是系统指令

经过一段时间的研究和实践，我发现 Copilot 这类 AI 工具实际上可以被深度"引导"，甚至达到一种"洗脑"的效果，让它们按照我们的意愿来行动。

它们并不是魔术盒子，而是遵循一套输入-输出原则的系统。如果我们能给它提供明确的指导和原则，它就能相应地调整自己的输出。

这个思路促使我整理了一个专门用来给 GitHub Copilot"洗脑"的指令集：[prompts](https://github.com/cuipengfei/prompts)。

这个仓库里不是代码，而是一系列指导 AI 行为的 Markdown 文件。每个文件就像是给 AI 的一份规范或指南，告诉它应该怎样思考和行动。

## 这套指令能解决什么问题？

使用 AI 编程助手时，我们通常会遇到这些问题：

- 生成的代码能运行，但结构混乱，难以维护
- 没有考虑边界情况和异常处理
- 代码风格不一致，命名随意
- 缺乏适当的测试覆盖
- 不遵循项目已有的架构模式

这套指令集就是为了解决这些问题而设计的。它告诉 AI 该如何思考软件设计、如何编写清晰的代码、如何进行测试驱动开发，以及如何分解复杂问题。

## 指令集的构成

整个指令集分为几个主要部分：

1. **核心行为定义**：这部分告诉 AI 应该如何进行思考和工作，包括：

   - 如何保持项目知识的连贯性（memory-bank）
   - 如何有条理地回应用户（response-and-prompt-guidelines）
   - 如何遵循 TDD 工作流（programming-workflow）
   - 如何分解复杂任务（workflow-and-task-splitting）

2. **代码质量规范**：这部分告诉 AI 什么是好代码，什么是坏代码：

   - 代码标准和最佳实践（code-standards）
   - 代码异味和应避免的反模式（avoid-bad-smells）
   - 如何编写有效的测试（testing-guidelines）

3. **流程模板**：这部分提供了从需求到实现的结构化方法：

   - 如何将模糊的想法转化为明确的计划（req）
   - 如何协助业务分析师编写用户故事（ba）

4. **工具使用指南**：这部分包含了一些高级技巧：
   - 如何使用顺序思考解决问题（sequential-thinking）
   - 快捷指令系统（shortcut-system-instruction）

## 这些“作战条令”是如何生效的？

你可能会好奇，为什么几份 Markdown 文件就能驯服一个复杂的 AI？

其根本原因在于，我们利用了大型语言模型的一个核心特性：**它是一个基于上下文的、概率性的序列生成器**。它本身没有真正的“理解”或“意识”，它的所有行为都是在预测“在当前上下文中，下一个最可能的词是什么”。

因此，这套指令的本质，就是一场**“上下文污染”（Context Contamination）**，或者说**“概率空间操纵”（Probability Space Manipulation）**。

通过在它的工作环境中注入一套强有力的、结构化的规则（我们的“作战条令”），我们极大地改变了它进行概率计算的“初始条件”。当“编写单元测试”、“考虑异常”这些概念在上下文中被反复强调时，生成符合这些规范的代码的概率就被显著提高了。

我们不是在“教”它，而是在**塑造一个让它“不得不”表现得更专业的环境**。

这套“作战条令”的核心，就是用规则约束 AI 的“自由意志”：
- **“慢思考”条令**，强制它在行动前必须进行“沙盘推演”（展示思考过程）。
- **“自我批判”条令**，要求它在每次“战斗”后必须提交“战后复盘报告”（自我评估）。
- **结构化的模板**，则像是规定了标准的“军事作业程序”（SOP），确保它在任何情况下都能做出标准、可靠的战术动作。

说白了，这套指令的核心就是不让 AI "想当然"。它必须按照预设的流程来工作，该问的问题不能跳过，该考虑的边界情况不能遗漏。

## 如何在实际工作中使用这套指令

经过实践，我发现在 VS Code 中配置 Copilot 使用这些指令非常简单：

1. 打开 VS Code 设置（Ctrl+, 或 Cmd+,）
2. 搜索 `github.copilot.chat.codeGeneration.instructions`
3. 添加指向指令文件的配置，例如：

```jsonc
"github.copilot.chat.codeGeneration.instructions": [
    { "text": "避免生成与公共代码完全匹配的代码" },
    { "file": "../prompts/.github/instructions/req.md" },
    { "file": "../prompts/.github/instructions/ba.md" },
    // 其它指令文件...
    { "file": "../prompts/.github/instructions/shortcut-system-instruction.md" }
]
```

需要注意的是，文件路径要正确。这里的路径是相对于你的 workspace 的。如果你的 prompts 仓库和当前项目不在同一位置，可能需要调整路径。

设置完成后，你会发现 Copilot 生成的代码质量明显提升：更规范、更健壮、考虑更周全。

## 一点思考：我们究竟在训练谁？

为 AI 制定“作战条令”的过程，其实和带新人有些相似 —— 你需要清晰地表达期望，提供良好的指导和范例，然后持续进行纠正和反馈。

但更有趣的是，这个过程在某种程度上也是对我们自己的“训练”。为了能给 AI 写出清晰的指令，我们必须首先在自己脑中将“好的代码”、“好的设计”、“好的流程”这些模糊的概念给形式化、结构化。

我们究竟是在训练 AI，还是在通过训练 AI 的过程，强迫自己进行更深层次的思考，从而成为更好的工程师？

这套指令系统的价值，或许不仅在于提升了 AI 的输出质量，更在于它像一面镜子，照见了我们自身在软件工程实践中的知识盲区，并促使我们去填补它。

---

如果你也在使用 AI 编程助手，不妨试试这套“作战条令”。如果有任何想法或改进建议，欢迎到 [prompts](https://github.com/cuipengfei/prompts) 仓库提交 PR 或 Issue。
